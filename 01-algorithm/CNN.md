


CNN 的核心架构通过 “卷积-激活-池化” 的交替堆叠，逐层提取从低级到高级的特征，最终通过全连接层输出结果。其设计巧妙结合了局部感知、权值共享、平移不变性等特性，使其成为计算机视觉领域的基石模型。

卷积神经网络（Convolutional Neural Network, CNN）是深度学习中用于处理图像、视频、语音等具有空间或时序结构数据的核心模型。其核心架构由以下几个关键组件构成：





# 输入层（Input Layer）

功能：接收原始数据（如图像的像素矩阵）。

特点：需标准化（如归一化到 [0,1] 或 [-1,1]）以加速训练。

示例：输入图像尺寸为 28×28×3（RGB三通道）。




# 卷积层（Convolutional Layer）

功能：提取局部特征（如边缘、纹理等）。

核心操作：

卷积核（Filter）：滑动窗口在输入数据上计算局部区域的加权和。

特征图（Feature Map）：每个卷积核生成一个特征图，捕捉特定模式。

关键参数：

卷积核尺寸（如 3×3、5×5）。

步长（Stride）：滑动步长（如 1 或 2）。

填充（Padding）：边缘补零（same 保持尺寸，valid 不填充）。

数学形式：

$$
output(i,j)=\sum_{m}^{}{\sum_{n}^{}{input(i+m,j+n)⋅kernel(m,n)+offset}}
$$





# 激活函数（Activation Function）

功能：引入非线性，增强模型表达能力。

常用类型：

ReLU（Rectified Linear Unit）：f(x) = max(0, x)（缓解梯度消失，计算高效）。

Sigmoid、Tanh（较少用于中间层，多用于输出层）。

Leaky ReLU、Swish（改进非线性特性）。




# 池化层（Pooling Layer）

功能：下采样（降维），增强平移不变性，减少计算量。

常见操作：

最大池化（Max Pooling）：取局部区域最大值（保留显著特征）。

平均池化（Average Pooling）：取局部区域平均值（平滑特征）。

参数：池化窗口大小（如 2×2）和步长（通常等于窗口大小）






# 全连接层（Fully Connected Layer）

功能：整合全局特征，输出分类或回归结果。

特点：

每个神经元与前一层的所有神经元连接。

通常位于网络末端（如分类任务中的类别概率输出）。

示例：将特征图展平后输入全连接层，输出 10 维向量（对应 10 分类）。






# 输出层（Output Layer）

功能：根据任务类型生成最终结果。

常见形式：

分类任务：Softmax 函数输出概率分布（如 [0.1, 0.7, 0.2]）。

回归任务：线性输出（如预测坐标值、价格等）。



# 其他辅助组件

批量归一化（Batch Normalization）：

加速训练，缓解梯度消失/爆炸，减少对初始化的敏感度。

Dropout：

随机丢弃部分神经元，防止过拟合。

残差连接（Residual Connection）：

解决深层网络梯度退化问题（如 ResNet 中的跳跃连接）。




以经典的 LeNet-5 为例：

```
输入层 → 卷积层 → 激活函数（ReLU） → 池化层 → 卷积层 → 激活函数 → 池化层 → 全连接层 → 输出层（Softmax）
```








